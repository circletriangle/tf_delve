{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import Clone_Model\n",
    "import rsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./cloning_eager_dis/checkpoints/cloning/default_checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "log_dir_clone = \"./cloning_eager_dis/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_clone, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 steps, validate on 1 steps\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.1866 - val_loss: 1.7910\n",
      "RESET Weights!\n",
      "RESET Weights!\n",
      "RESET Weights!\n",
      "RESET Weights!\n",
      "RESET Weights!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected model_input to have 2 dimensions, but got array with shape (1, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-63fc8cab4945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClone_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msatify_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m clone.compile(optimizer=keras.optimizers.Adam(),\n",
      "\u001b[0;32m~/Desktop/Thesis/New_Repo/Clone_Model.py\u001b[0m in \u001b[0;36msatify_model\u001b[0;34m(model, compile_dict)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m#z_in = np.ones(shape=model.layers[0].input_shape[-2:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mz_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wrong: predictions don't match original\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 707\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    708\u001b[0m     return predict_loop(\n\u001b[1;32m    709\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2306\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2308\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2333\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2335\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected model_input to have 2 dimensions, but got array with shape (1, 28, 28)"
     ]
    }
   ],
   "source": [
    "#      CLONE MODEL EAGER DISABLED\n",
    "###########################################\n",
    "importlib.reload(rsc)\n",
    "importlib.reload(Clone_Model)\n",
    "\n",
    "#K.clear_session() \n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "batch_size = None #doesnt work/conflict tensorboard_callback\n",
    "train, test = rsc.get_titanic_dataset()\n",
    "\n",
    "\n",
    "\n",
    "model = rsc.get_model(None)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    run_eagerly = tf.executing_eagerly()\n",
    "    )\n",
    "\n",
    "\n",
    "tensorboard_callback.set_model(model)\n",
    "\n",
    "history = model.fit(train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=1, \n",
    "                    steps_per_epoch=3, \n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[])\n",
    "\n",
    "\n",
    "clone = Clone_Model.satify_model(model)\n",
    "\n",
    "clone.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              run_eagerly = tf.executing_eagerly())\n",
    "\n",
    "sat_cb = Clone_Model.sat_results()\n",
    "\n",
    "\n",
    "history = clone.fit(train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=1,\n",
    "                    steps_per_epoch=3,\n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[sat_cb])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 2.0697 - accuracy: 0.8417 - val_loss: 0.2230 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3857 - accuracy: 0.9061 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 11s 4ms/step - loss: 0.3005 - accuracy: 0.9265 - val_loss: 0.2273 - val_accuracy: 0.9000\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2692 - accuracy: 0.9336 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2571 - accuracy: 0.9398 - val_loss: 0.1695 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "#      CLASSIFY MNIST EAGER DISABLED\n",
    "###########################################\n",
    "importlib.reload(rsc)\n",
    "importlib.reload(Clone_Model)\n",
    "\n",
    "K.clear_session() \n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "#problem source\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "batch_size = 20 \n",
    "\n",
    "train, test = rsc.get_mnist()\n",
    "\n",
    "model = rsc.get_model_unitlist(hidden_layers_spec=[128])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly = False\n",
    "    )\n",
    "\n",
    "\n",
    "tensorboard_callback.set_model(model)\n",
    "\n",
    "history = model.fit(train[0],\n",
    "                    train[1],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=None, \n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'tensorflow.python.keras.layers.core.Flatten'>\n",
      "Clone_Model.satify_model() end.\n",
      "\n",
      "Logs from batch callback: {'loss': 4.517240047454834, 'accuracy': 0.8333333134651184, 'o_s_sl_metric': -1.1663865540721567}\n",
      "\n",
      "K.GETVALUE o_s satlayer: 3.703924379946267\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.5172 - accuracy: 0.8333 - o_s_sl_metric: -1.1664\n",
      "Logs from batch callback: {'loss': 4.055177688598633, 'accuracy': 0.8888888955116272, 'o_s_sl_metric': 0.33361344592784326}\n",
      "\n",
      "K.GETVALUE o_s satlayer: 6.703924379946267\n",
      "\n",
      "Logs from batch callback: {'loss': 3.615018606185913, 'accuracy': 0.9166666865348816, 'o_s_sl_metric': 1.8336134459278435}\n",
      "\n",
      "K.GETVALUE o_s satlayer: 9.703924379946267\n",
      "\n",
      "Logs from epoch callback: {'loss': 3.615018606185913, 'accuracy': 0.9166666865348816, 'o_s_sl_metric': 1.8336134459278435, 'val_loss': 6.349829196929932, 'val_accuracy': 1.0, 'val_o_s_sl_metric': 7.833613445927844}\n",
      "\n",
      "K.print_tensor()\n",
      " [0.0732487366637199 0.021791875520908777 0.048295801551710177 ... -0.019788278349186089 463.16646331238883 -0.14746615918849137]\n",
      "\n",
      "K.GETVALUE o_s satlayer: 12.703924379946267\n",
      "\n",
      "Layer dense sat_result: [0.0625]\n",
      "Observed samples sat_layer: 12.703924379946267\n",
      "o_s aggregator: []\n",
      "r_s aggregator: [128]\n",
      "s_s aggregator: [128 128]\n",
      "Sublayer-sat from sublayer_vals: [0.0625]\n",
      "Sublayer-sat from aggr_vals: [0.0625]\n",
      "SatFunctions-sat from aggr_vals: [0.0625]\n",
      "\n",
      "Comparing Layer_o_s and Aggregator_o_s:\n",
      "\n",
      "Shape Layer_o_s: []\n",
      "Shape Aggregator_o_s: []\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: 0.7039243799462671\n",
      "Avg Ratio Diff/Value of Layer_o_s elements: 0.05540999449409856\n",
      "Avg Ratio Diff/Value of Aggregator_o_s elements: 0.05866036499552226\n",
      "Max Ratio Diff/Value Layer_o_s: 0.05540999449409856\n",
      "Max Ratio Diff/Value Aggregator_o_s: 0.05866036499552226\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Comparing Layer_r_s and Aggregator_r_s:\n",
      "\n",
      "Shape Layer_r_s: [128]\n",
      "Shape Aggregator_r_s: [128]\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: -0.003808855212917407\n",
      "Avg Ratio Diff/Value of Layer_r_s elements: 0.8438913168513351\n",
      "Avg Ratio Diff/Value of Aggregator_r_s elements: inf\n",
      "Max Ratio Diff/Value Layer_r_s: 1.0\n",
      "Max Ratio Diff/Value Aggregator_r_s: inf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Comparing Layer_s_s and Aggregator_s_s:\n",
      "\n",
      "Shape Layer_s_s: [128 128]\n",
      "Shape Aggregator_s_s: [128 128]\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: 0.00029312515452962546\n",
      "Avg Ratio Diff/Value of Layer_s_s elements: 0.9924318119176787\n",
      "Avg Ratio Diff/Value of Aggregator_s_s elements: inf\n",
      "Max Ratio Diff/Value Layer_s_s: 1.0\n",
      "Max Ratio Diff/Value Aggregator_s_s: inf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Logs from epoch callback: {'loss': 3.615018606185913, 'accuracy': 0.9166666865348816, 'o_s_sl_metric': 1.8336134459278435, 'val_loss': 6.349829196929932, 'val_accuracy': 1.0, 'val_o_s_sl_metric': 7.833613445927844}\n",
      "\n",
      "K.print_tensor()\n",
      " [-277.90807851003439 124.47754207105451 120.19122608797718 ... 368.3146160252445 -64.7550191777963 200.31081034445702]\n",
      "\n",
      "K.GETVALUE o_s satlayer: 10.833613445927844\n",
      "\n",
      "Layer dense_1 sat_result: [0.5]\n",
      "Observed samples sat_layer: 10.833613445927844\n",
      "o_s aggregator: []\n",
      "r_s aggregator: [10]\n",
      "s_s aggregator: [10 10]\n",
      "Sublayer-sat from sublayer_vals: [0.5]\n",
      "Sublayer-sat from aggr_vals: [0.5]\n",
      "SatFunctions-sat from aggr_vals: [0.5]\n",
      "\n",
      "Comparing Layer_o_s and Aggregator_o_s:\n",
      "\n",
      "Shape Layer_o_s: []\n",
      "Shape Aggregator_o_s: []\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: -1.1663865540721563\n",
      "Avg Ratio Diff/Value of Layer_o_s elements: 0.10766366733442752\n",
      "Avg Ratio Diff/Value of Aggregator_o_s elements: 0.09719887950601303\n",
      "Max Ratio Diff/Value Layer_o_s: 0.10766366733442752\n",
      "Max Ratio Diff/Value Aggregator_o_s: 0.09719887950601303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Comparing Layer_r_s and Aggregator_r_s:\n",
      "\n",
      "Shape Layer_r_s: [10]\n",
      "Shape Aggregator_r_s: [10]\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: -0.109343180116133\n",
      "Avg Ratio Diff/Value of Layer_r_s elements: 0.0026193498212033726\n",
      "Avg Ratio Diff/Value of Aggregator_r_s elements: 0.0025994834289207276\n",
      "Max Ratio Diff/Value Layer_r_s: 0.013750844267616783\n",
      "Max Ratio Diff/Value Aggregator_r_s: 0.013564323369368995\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Comparing Layer_s_s and Aggregator_s_s:\n",
      "\n",
      "Shape Layer_s_s: [10 10]\n",
      "Shape Aggregator_s_s: [10 10]\n",
      "Tensors equal -> False\n",
      "Mean Difference of elements: 0.02745582450741267\n",
      "Avg Ratio Diff/Value of Layer_s_s elements: 0.00030020375415569777\n",
      "Avg Ratio Diff/Value of Aggregator_s_s elements: 0.00029862926376399157\n",
      "Max Ratio Diff/Value Layer_s_s: 0.012417068143528274\n",
      "Max Ratio Diff/Value Aggregator_s_s: 0.012264775589271212\n",
      "\n",
      "\n",
      "\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3.6150 - accuracy: 0.9167 - o_s_sl_metric: 1.8336 - val_loss: 6.3498 - val_accuracy: 1.0000 - val_o_s_sl_metric: 7.8336\n"
     ]
    }
   ],
   "source": [
    "#      CLONE MNIST MODEL EAGER DISABLED\n",
    "###########################################\n",
    "importlib.reload(rsc)\n",
    "importlib.reload(Clone_Model)\n",
    "#K.clear_session() \n",
    "\n",
    "#This mixed v1 v2 TF and can only cause problems.\n",
    "#-> pass eager=False to model.fit() instead!!\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "clone = Clone_Model.satify_model(model, {'run_eagerly' : True})\n",
    "\n",
    "sat_cb = Clone_Model.sat_results()\n",
    "\n",
    "history = clone.fit(train[0],\n",
    "                    train[1],\n",
    "                    batch_size=3,\n",
    "                    epochs=1,\n",
    "                    steps_per_epoch=3,\n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[sat_cb])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "{'validation_data': None, 'model': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fe02832fc90>, '_chief_worker_only': None, 'history': {'loss': [0.19146684805552164], 'accuracy': [0.9508833], 'val_loss': [0.24173198640346527], 'val_accuracy': [0.947]}, 'params': {'batch_size': 3, 'epochs': 1, 'steps': 3, 'samples': 3, 'verbose': 1, 'do_validation': True, 'metrics': ['loss', 'accuracy', 'o_sdense', 'o_sdense_1', 'val_loss', 'val_accuracy', 'val_o_sdense', 'val_o_sdense_1']}, 'epoch': [0]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "print(history.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Warum macht tf probleme und zeigt auf auskommentierten code?\n",
    "        #Default to k=1 if first EVal explains delta of variance alone \n",
    "        #TODO change condition so graph mode works without tf.function\n",
    "        #if not \n",
    "        #    #cond = tf.constant([True], dtype=tf.bool)\n",
    "            #print(\"cond with default catch: {}\".format(cond))   \n",
    "        \"\"\"    \n",
    "        \n",
    "    \n",
    "    #k = max(len(tf.where(cond)), 1 ) #TODO use min(1,tf.where()) instead of checking above\n",
    "        \n",
    "        #print(\"tf.where(): {}\".format(tf.where(cond)))\n",
    "        #print(\"K: in ll_fun {}\".format(k))\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
