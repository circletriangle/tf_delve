{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "\n",
    "import Clone_Model\n",
    "import rsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./cloning_eager_dis/checkpoints/cloning/default_checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "log_dir_clone = \"./cloning_eager_dis/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_clone, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 steps, validate on 1 steps\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5971 - val_loss: 1.2106\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2266 - val_loss: 1.7522\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4081 - val_loss: 0.7825\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6574 - val_loss: 0.6052\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0198 - val_loss: 0.6231\n",
      "Train on 3 steps, validate on 1 steps\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9545 - my_placeholder_metric_dense_1: 2534.1416 - observed_samples_sat_dense_1: 0.0000e+00 - my_placeholder_metric_dense_2: 763.4334 - observed_samples_sat_dense_2: 0.0000e+00 - my_placeholder_metric_dense_3: 645.1130 - observed_samples_sat_dense_3: 0.0000e+00 - my_placeholder_metric_dense_4: 388.9065 - observed_samples_sat_dense_4: 0.0000e+00 - my_placeholder_metric_predictions: 20.0000 - observed_samples_sat_predictions: 0.0000e+00 - val_loss: 0.6590 - val_my_placeholder_metric_dense_1: 2310.2205 - val_observed_samples_sat_dense_1: 0.0000e+00 - val_my_placeholder_metric_dense_2: 676.1725 - val_observed_samples_sat_dense_2: 0.0000e+00 - val_my_placeholder_metric_dense_3: 602.3961 - val_observed_samples_sat_dense_3: 0.0000e+00 - val_my_placeholder_metric_dense_4: 351.3514 - val_observed_samples_sat_dense_4: 0.0000e+00 - val_my_placeholder_metric_predictions: 20.0000 - val_observed_samples_sat_predictions: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#      CLONE MODEL EAGER DISABLED\n",
    "###########################################\n",
    "importlib.reload(rsc)\n",
    "importlib.reload(Clone_Model)\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "batch_size = None #doesnt work/conflict tensorboard_callback\n",
    "train, test = rsc.get_titanic_dataset()\n",
    "\n",
    "\n",
    "\n",
    "model = rsc.get_model(None)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    run_eagerly = tf.executing_eagerly()\n",
    "    )\n",
    "\n",
    "\n",
    "tensorboard_callback.set_model(model)\n",
    "\n",
    "history = model.fit(train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=5, \n",
    "                    steps_per_epoch=3, \n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "clone_fn = Clone_Model.clone_fn\n",
    "clone = tf.keras.models.clone_model(model, input_tensors=model.inputs, clone_function=clone_fn)\n",
    "\n",
    "z_in = np.ones(shape=(20,4))\n",
    "assert np.allclose(model.predict(z_in), clone.predict(z_in)), \"Wrooong\"\n",
    "\"\"\"\n",
    "clone = Clone_Model.satify_model(model)\n",
    "\n",
    "clone.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              run_eagerly = tf.executing_eagerly())\n",
    "\n",
    "history = clone.fit(train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=1,\n",
    "                    steps_per_epoch=3,\n",
    "                    validation_data=test, \n",
    "                    validation_steps=1, \n",
    "                    callbacks=[])\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
